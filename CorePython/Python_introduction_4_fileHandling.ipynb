{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0de279",
   "metadata": {},
   "source": [
    "# File Handling Basics\n",
    "\n",
    "In Data Engineering and AI workflows, files are a primary way to **ingest**, **store**, and **exchange** data (logs, CSV/JSON, model artifacts, configs).\n",
    "\n",
    "## Learning goals\n",
    "By the end of this notebook, you should be able to:\n",
    "- Open files safely using `with open(...)`\n",
    "- Choose the correct **mode** (`r`, `w`, `a`, `x`, `b`) and handle **encoding**\n",
    "- Read files in a **memory-safe** way (streaming line-by-line)\n",
    "- Write simple datasets (including **JSON Lines / JSONL**)\n",
    "- Handle common file errors (`FileNotFoundError`, permissions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b451def",
   "metadata": {},
   "source": [
    "## Paths and the working directory\n",
    "\n",
    "When your script runs, Python has a **current working directory (CWD)**. Relative paths (like `\"data/file.txt\"`) are resolved from the CWD.\n",
    "\n",
    "For portable code, prefer `pathlib.Path` for path building.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "\n",
    "data_dir = cwd / \"data\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "sample_path = data_dir / \"sample.txt\"\n",
    "print(\"Sample file path:\", sample_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c077f",
   "metadata": {},
   "source": [
    "## Creating a small sample file\n",
    "\n",
    "We create a small text file so everyone can run the same examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb477f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    \"id,name,score\\n\",\n",
    "    \"1,Alice,98\\n\",\n",
    "    \"2,Bob,87\\n\",\n",
    "    \"3,Carol,91\\n\",\n",
    "    \"4,Dan,73\\n\",\n",
    "    \"5,Eve,88\\n\",\n",
    "]\n",
    "\n",
    "with open(sample_path, \"w\", encoding=\"utf-8\") as file_handler:\n",
    "    file_handler.writelines(lines)\n",
    "\n",
    "print(\"Wrote\", len(lines), \"lines to\", sample_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbf8c3",
   "metadata": {},
   "source": [
    "## Opening files: modes, text vs binary, encoding\n",
    "\n",
    "`open(path, mode, encoding=...)` returns a **file handle** (a stream).\n",
    "\n",
    "Common modes:\n",
    "- `\"r\"`: read (fails if file does not exist)\n",
    "- `\"w\"`: write (overwrites if file exists)\n",
    "- `\"a\"`: append (creates if missing)\n",
    "- `\"x\"`: create (fails if file already exists)\n",
    "- Add `\"b\"` for binary: `\"rb\"`, `\"wb\"` (images, compressed files, parquet bytes)\n",
    "\n",
    "Best practice for text files:\n",
    "- Always specify `encoding=\"utf-8\"` unless you have a reason not to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ebc72c",
   "metadata": {},
   "source": [
    "## Reading patterns\n",
    "\n",
    "### Read the entire file (easy, not always scalable)\n",
    "Use `.read()` only when you know the file is small enough to fit in memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_path, \"r\", encoding=\"utf-8\") as file_handler:\n",
    "    content = file_handler.read()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a17bd",
   "metadata": {},
   "source": [
    "### Stream line-by-line (recommended for large files)\n",
    "\n",
    "Iterating over a file handle reads lazily and avoids loading everything into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_path, \"r\", encoding=\"utf-8\") as file_handler:\n",
    "    for line in file_handler:\n",
    "        print(line.rstrip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9e4cf",
   "metadata": {},
   "source": [
    "### Peek at the first *N* lines (common DE task)\n",
    "\n",
    "Useful when exploring unknown files or validating ingestion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18738411",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "\n",
    "with open(sample_path, \"r\", encoding=\"utf-8\") as file_handler:\n",
    "    for i, line in enumerate(file_handler):\n",
    "        if i == N:\n",
    "            break\n",
    "        print(line.rstrip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305b230",
   "metadata": {},
   "source": [
    "### Read in chunks (for very large files)\n",
    "\n",
    "Chunking is useful for large text or binary files (e.g., upload/download, hashing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 16  # bytes/characters in text mode depends on encoding; keep demos small\n",
    "\n",
    "with open(sample_path, \"r\", encoding=\"utf-8\") as file_handler:\n",
    "    while True:\n",
    "        chunk = file_handler.read(chunk_size)\n",
    "        if not chunk:\n",
    "            break\n",
    "        print(repr(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2344f",
   "metadata": {},
   "source": [
    "## Writing patterns\n",
    "\n",
    "### Write vs append\n",
    "- `\"w\"` overwrites the file\n",
    "- `\"a\"` appends at the end\n",
    "\n",
    "Remember: `write()` does not add newlines automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c66b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = data_dir / \"log.txt\"\n",
    "\n",
    "with open(log_path, \"w\", encoding=\"utf-8\") as file_handler:\n",
    "    file_handler.write(\"Start of log\\n\")\n",
    "\n",
    "with open(log_path, \"a\", encoding=\"utf-8\") as file_handler:\n",
    "    file_handler.write(\"Another line\\n\")\n",
    "\n",
    "print(\"Log content:\")\n",
    "with open(log_path, \"r\", encoding=\"utf-8\") as file_handler:\n",
    "    print(file_handler.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd48ef",
   "metadata": {},
   "source": [
    "### Create-only mode (`\"x\"`) to avoid accidental overwrites\n",
    "\n",
    "This is a safety pattern when generating outputs in pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45168e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_path = data_dir / \"created_once.txt\"\n",
    "\n",
    "try:\n",
    "    with open(safe_path, \"x\", encoding=\"utf-8\") as file_handler:\n",
    "        file_handler.write(\"This file is created only if it does not exist.\\n\")\n",
    "    print(\"Created:\", safe_path.name)\n",
    "except FileExistsError:\n",
    "    print(\"Already exists:\", safe_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468ccf7",
   "metadata": {},
   "source": [
    "## Why `with` matters (context managers)\n",
    "\n",
    "`with open(...)` ensures the file is **closed** even if an exception occurs.\n",
    "\n",
    "Technical detail:\n",
    "- `__enter__()` runs at the start of the block\n",
    "- `__exit__()` runs at the end (even on errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b45da2e",
   "metadata": {},
   "source": [
    "## Common errors and defensive patterns\n",
    "\n",
    "Most common issues:\n",
    "- File does not exist: `FileNotFoundError`\n",
    "- Permission problems: `PermissionError`\n",
    "- Wrong encoding: `UnicodeDecodeError`\n",
    "\n",
    "In DE pipelines, fail fast with clear messages or implement a fallback strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_path = data_dir / \"does_not_exist.txt\"\n",
    "\n",
    "try:\n",
    "    with open(missing_path, \"r\", encoding=\"utf-8\") as file_handler:\n",
    "        file_handler.read()\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {missing_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc263c",
   "metadata": {},
   "source": [
    "## Data Engineering example: JSON Lines (JSONL)\n",
    "\n",
    "JSONL is common for logs and event streams:\n",
    "- One JSON object per line\n",
    "- Stream-friendly: you can process line-by-line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b48f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "records = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"score\": 98},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"score\": 87},\n",
    "    {\"id\": 3, \"name\": \"Carol\", \"score\": 91},\n",
    "]\n",
    "\n",
    "jsonl_path = data_dir / \"records.jsonl\"\n",
    "\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as file_handler:\n",
    "    for record in records:\n",
    "        file_handler.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "print(\"Wrote JSONL:\", jsonl_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd433cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSONL line-by-line (streaming)\n",
    "import json\n",
    "\n",
    "parsed = []\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as file_handler:\n",
    "    for line in file_handler:\n",
    "        parsed.append(json.loads(line))\n",
    "\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dee637",
   "metadata": {},
   "source": [
    "# Options to open a file\n",
    "\n",
    "Here is a table of the options available for reading a file in Python using the `open` function:\n",
    "\n",
    "Option | Description\n",
    "------- | -----------\n",
    "\"r\" | Open the file for reading (default).\n",
    "\"w\" | Open the file for writing. If the file already exists, its contents will be overwritten. If the file does not exist, a new file will be created.\n",
    "\"a\" | Open the file for appending. Any new data written to the file will be added to the end of the file, without overwriting its existing contents.\n",
    "\"x\" | Open the file for exclusive creation. If the file already exists, an error will be raised. This option is only available in Python 3.3 and later.\n",
    "\"b\" | Open the file in binary mode. The file contents are read as binary data and can be manipulated as bytes.\n",
    "\"+\" | Open the file for both reading and writing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de0a3a",
   "metadata": {},
   "source": [
    "## Quick exercises (3â€“7 minutes each)\n",
    "\n",
    "1) **Peek**: Print the first 5 lines of `sample.txt` (no `.read()`).\n",
    "2) **Count**: Count how many lines are in `sample.txt`.\n",
    "3) **Append**: Append a new log line with your name to `log.txt`.\n",
    "4) **JSONL**: Add one new record to `records.jsonl` using append mode.\n",
    "5) **Defensive open**: Try to open a missing file and print a clean error message.\n",
    "\n",
    "You can implement them in a new code cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee4795",
   "metadata": {},
   "source": [
    "> Content created by **Carlos Cruz-Maldonado**.  \n",
    "> Updated and expanded for the training session.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
